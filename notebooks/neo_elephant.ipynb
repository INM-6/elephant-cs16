{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Elephant and Neo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "*Neo* provides a set of classes for representing time series data (`SpikeTrain`, `AnalogSignalArray`, etc.), for representing the hierarchical arrangement of data in an experiment (`Segment`, `Block`) and for representing the relationship between spike trains and recording channels (`Unit`). Neo is used by a number of data visualization tools ([OpenElectrophy](http://neuralensemble.org/OpenElectrophy), [SpykeViewer](https://spyke-viewer.readthedocs.org/)) and by the [PyNN](http://neuralensemble.org/PyNN) metasimulator.\n",
    "\n",
    "*Elephant* is a data analysis library built on Neo. It aims to provide a standard library for electrophysiology data analysis (in future, also imaging data analysis), merging functions from OpenElectrophy, SpykeViewer and [NeuroTools](http://neuralensemble.org/NeuroTools)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Neo: electrophysiology data objects, I/O**\n",
    "    \n",
    "![](http://neo.readthedocs.org/en/latest/_images/neologo.png)\n",
    "\n",
    "**Elephant: electrophysiology data analysis**\n",
    "\n",
    "![](http://elephant.readthedocs.org/en/latest/_static/elephant_logo_sidebar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Documentation\n",
    "\n",
    "- http://neo.readthedocs.org/\n",
    "- http://elephant.readthedocs.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "Using Anaconda (e.g. on Windows/Mac):\n",
    "\n",
    "    $ conda create -n neuroscience numpy scipy ipython matplotlib pip\n",
    "    \n",
    "    $ source activate neuroscience\n",
    "    \n",
    "On Ubuntu/Debian:\n",
    "\n",
    "    $ sudo apt-get install python-numpy python-scipy python-matplotlib python-pip ipython\n",
    "    \n",
    "    $ virtualenv --system-site-packages ~/env/neuroscience\n",
    "    \n",
    "    $ source ~/env/neuroscience/bin/activate\n",
    "  \n",
    "Then:\n",
    "  \n",
    "    $ pip install quantities\n",
    "    \n",
    "    $ pip install git+https://github.com/NeuralEnsemble/python-neo.git@apibreak#egg=neo-apibreak\n",
    "    \n",
    "    $ pip install elephant\n",
    "\n",
    "(Note that Elephant requires the development version of Neo (the future 0.4 release))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://neo.readthedocs.org/en/latest/_images/neologo.png)\n",
    "\n",
    "- a Python package for representing electrophysiology data in Python\n",
    "- support for reading a wide range of neurophysiology file formats, including Spike2, NeuroExplorer, AlphaOmega, Axon, Blackrock, Plexon, Tdt\n",
    "- support for writing to a subset of these formats plus general formats including MATLAB, HDF5\n",
    "- deliberately limited to represention of data, with no functions for data analysis or visualization\n",
    "- based on NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://neo.readthedocs.org/en/latest/_images/base_schematic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from neo.io import ElphyIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = ElphyIO(\"data/5106CM3.DAT\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Block with 8 segments\n",
       " # segments (N=8)\n",
       " 0: Segment with 3 analogsignals\n",
       "    name: 'episode 1'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614854 float64 values\n",
       "       annotations: {'channel_name': 'episode 2, channel 2',\n",
       "         't_stop': array(62715.10799999999) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62715.108 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614854 float64 values\n",
       "       annotations: {'channel_name': 'episode 2, channel 3',\n",
       "         't_stop': array(62715.10799999999) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62715.108 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15372 float64 values\n",
       "       annotations: {'channel_name': 'episode 2, channel 4',\n",
       "         't_stop': array(62713.68) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62717.76 ms\n",
       "    # analogsignalarrays (N=0)\n",
       " 1: Segment with 3 analogsignals\n",
       "    name: 'episode 2'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614817 float64 values\n",
       "       annotations: {'channel_name': 'episode 3, channel 2',\n",
       "         't_stop': array(62711.333999999995) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62711.334 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614817 float64 values\n",
       "       annotations: {'channel_name': 'episode 3, channel 3',\n",
       "         't_stop': array(62711.333999999995) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62711.334 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15371 float64 values\n",
       "       annotations: {'channel_name': 'episode 3, channel 4',\n",
       "         't_stop': array(62709.6) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62713.68 ms\n",
       "    # analogsignalarrays (N=0)\n",
       " 2: Segment with 3 analogsignals\n",
       "    name: 'episode 3'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614847 float64 values\n",
       "       annotations: {'channel_name': 'episode 4, channel 2',\n",
       "         't_stop': array(62714.39399999999) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62714.394 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614847 float64 values\n",
       "       annotations: {'channel_name': 'episode 4, channel 3',\n",
       "         't_stop': array(62714.39399999999) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62714.394 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15372 float64 values\n",
       "       annotations: {'channel_name': 'episode 4, channel 4',\n",
       "         't_stop': array(62713.68) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62717.76 ms\n",
       "    # analogsignalarrays (N=0)\n",
       " 3: Segment with 3 analogsignals\n",
       "    name: 'episode 4'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614650 float64 values\n",
       "       annotations: {'channel_name': 'episode 5, channel 2',\n",
       "         't_stop': array(62694.198) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62694.3 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614650 float64 values\n",
       "       annotations: {'channel_name': 'episode 5, channel 3',\n",
       "         't_stop': array(62694.198) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62694.3 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15367 float64 values\n",
       "       annotations: {'channel_name': 'episode 5, channel 4',\n",
       "         't_stop': array(62693.28) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62697.36 ms\n",
       "    # analogsignalarrays (N=0)\n",
       " 4: Segment with 3 analogsignals\n",
       "    name: 'episode 5'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614841 float64 values\n",
       "       annotations: {'channel_name': 'episode 6, channel 2',\n",
       "         't_stop': array(62713.782) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62713.782 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614841 float64 values\n",
       "       annotations: {'channel_name': 'episode 6, channel 3',\n",
       "         't_stop': array(62713.782) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62713.782 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15372 float64 values\n",
       "       annotations: {'channel_name': 'episode 6, channel 4',\n",
       "         't_stop': array(62713.68) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62717.76 ms\n",
       "    # analogsignalarrays (N=0)\n",
       " 5: Segment with 3 analogsignals\n",
       "    name: 'episode 6'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614856 float64 values\n",
       "       annotations: {'channel_name': 'episode 7, channel 2',\n",
       "         't_stop': array(62715.312) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62715.312 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614856 float64 values\n",
       "       annotations: {'channel_name': 'episode 7, channel 3',\n",
       "         't_stop': array(62715.312) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62715.312 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15372 float64 values\n",
       "       annotations: {'channel_name': 'episode 7, channel 4',\n",
       "         't_stop': array(62713.68) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62717.76 ms\n",
       "    # analogsignalarrays (N=0)\n",
       " 6: Segment with 3 analogsignals\n",
       "    name: 'episode 7'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614832 float64 values\n",
       "       annotations: {'channel_name': 'episode 8, channel 2',\n",
       "         't_stop': array(62712.761999999995) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62712.864 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614832 float64 values\n",
       "       annotations: {'channel_name': 'episode 8, channel 3',\n",
       "         't_stop': array(62712.761999999995) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62712.864 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15371 float64 values\n",
       "       annotations: {'channel_name': 'episode 8, channel 4',\n",
       "         't_stop': array(62709.6) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62713.68 ms\n",
       "    # analogsignalarrays (N=0)\n",
       " 7: Segment with 3 analogsignals\n",
       "    name: 'episode 8'\n",
       "    # analogsignals (N=3)\n",
       "    0: AnalogSignal in 1.0 mV with 614650 float64 values\n",
       "       annotations: {'channel_name': 'episode 9, channel 2',\n",
       "         't_stop': array(62694.198) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62694.3 ms\n",
       "    1: AnalogSignal in 1.0 nA with 614650 float64 values\n",
       "       annotations: {'channel_name': 'episode 9, channel 3',\n",
       "         't_stop': array(62694.198) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 9.80392156863 1/ms\n",
       "       time: 0.0 ms to 62694.3 ms\n",
       "    2: AnalogSignal in 1.0 mV with 15367 float64 values\n",
       "       annotations: {'channel_name': 'episode 9, channel 4',\n",
       "         't_stop': array(62693.28) * ms}\n",
       "       channel index: None\n",
       "       sampling rate: 0.245098039216 1/ms\n",
       "       time: 0.0 ms to 62697.36 ms\n",
       "    # analogsignalarrays (N=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segment with 3 analogsignals\n",
       "name: 'episode 4'\n",
       "# analogsignals (N=3)\n",
       "0: AnalogSignal in 1.0 mV with 614650 float64 values\n",
       "   annotations: {'channel_name': 'episode 5, channel 2',\n",
       "     't_stop': array(62694.198) * ms}\n",
       "   channel index: None\n",
       "   sampling rate: 9.80392156863 1/ms\n",
       "   time: 0.0 ms to 62694.3 ms\n",
       "1: AnalogSignal in 1.0 nA with 614650 float64 values\n",
       "   annotations: {'channel_name': 'episode 5, channel 3',\n",
       "     't_stop': array(62694.198) * ms}\n",
       "   channel index: None\n",
       "   sampling rate: 9.80392156863 1/ms\n",
       "   time: 0.0 ms to 62694.3 ms\n",
       "2: AnalogSignal in 1.0 mV with 15367 float64 values\n",
       "   annotations: {'channel_name': 'episode 5, channel 4',\n",
       "     't_stop': array(62693.28) * ms}\n",
       "   channel index: None\n",
       "   sampling rate: 0.245098039216 1/ms\n",
       "   time: 0.0 ms to 62697.36 ms\n",
       "# analogsignalarrays (N=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].segments[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working with AnalogSignals and SpikeTrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "signal = data[0].segments[3].analogsignals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(9.803921568627452) * 1/ms"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(9.803921568627452) * kHz"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.sampling_rate.rescale('kHz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(62694.299999999996) * ms"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.0) * mV"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-85.94799169820536) * mV"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-72.47402198326392) * mV"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (16.0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f45600c5810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(signal.times.rescale('s'), signal)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Membrane potential (%s)\" % signal.dimensionality.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "zoom = signal[0.38*signal.size: 0.4*signal.size]\n",
    "zoom.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(zoom.times, zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import quantities as pq \n",
    "zoom2 = signal.time_slice(30*pq.s, 40*pq.s)\n",
    "plt.plot(zoom2.times, zoom2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from quantities import mV, ms, Hz\n",
    "from neo import SpikeTrain\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def extract_spikes(signal, threshold=-40*mV):\n",
    "    above_threshold = (signal > threshold).astype(int)\n",
    "    crossings = (above_threshold[1:] - above_threshold[:-1]) > 0\n",
    "    spike_times = signal.times[1:][crossings]\n",
    "    return SpikeTrain(spike_times, units='ms', t_stop=signal.t_stop, t_start=signal.t_start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "spikes = extract_spikes(zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spikes.magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spikes.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(zoom.times, zoom)\n",
    "plt.plot(spikes, -40*np.ones_like(spikes), 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(zoom.times, zoom)\n",
    "plt.plot(spikes, -40*np.ones_like(spikes), 'ro')\n",
    "plt.xlim(23850, 23870)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://elephant.readthedocs.org/en/latest/_static/elephant_logo_sidebar.png)\n",
    "\n",
    "- A community-developed Python toolbox for electrophysiology data analysis (in future, also optical imaging)\n",
    "- Aims to merge data analysis methods from NeuroTools, OpenElectrophy, SpykeViewer\n",
    "- Current functionality:\n",
    "    - Spike train statistics\n",
    "    - Signal processing\n",
    "    - Spectral analysis\n",
    "    - Spike-triggered average\n",
    "    - Stochastic spike train generation\n",
    "    - Spike train surrogates\n",
    "    - Data format conversions\n",
    "    - Spike train correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A note on versions\n",
    "\n",
    "Elephant requires the development version of Neo (the future version 0.4). In Neo 0.4, `AnalogSignal` and `AnalogSignalArray` will be merged; Elephant works only with `AnalogSignalArray`, so we need to convert our signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from neo import AnalogSignalArray\n",
    "signal_arr = AnalogSignalArray(signal.reshape(-1, 1),\n",
    "                               sampling_rate=signal.sampling_rate)\n",
    "zoom_arr = signal_arr[0.38*signal.size: 0.4*signal.size, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Signal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from elephant.signal_processing import butter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "high_pass = butter(zoom_arr, highpass_freq=50*Hz)\n",
    "low_pass = butter(zoom_arr, lowpass_freq=200*Hz)\n",
    "band_pass = butter(zoom_arr, lowpass_freq=200*Hz, highpass_freq=50*Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(zoom_arr.times, zoom_arr, 'b-',\n",
    "         high_pass.times, high_pass + 40*mV, 'g-',\n",
    "         low_pass.times, low_pass - 40*mV, 'r-')\n",
    "plt.xlabel(\"Time (%s)\" % zoom_arr.times.dimensionality.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spectral analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from elephant.spectral import welch_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "freqs, psd = welch_psd(signal_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(freqs, psd[0])\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"Frequency (%s)\" % freqs.dimensionality.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spike train statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from elephant.statistics import cv, lv, isi, fanofactor, mean_firing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spikes = extract_spikes(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "isis = isi(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "isis.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "isis.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "cv(isis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mean_firing_rate(spikes).rescale('Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from elephant.statistics import time_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binned_signal = time_histogram([spikes], 100*ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = binned_signal.times\n",
    "y = binned_signal[:, 0]\n",
    "plt.plot(x, y)\n",
    "plt.gca().fill_between(x, y, where=y>=0, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./elephant_dev/')\n",
    "import kernels\n",
    "import quantities as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = kernels.AlphaKernel(sigma=100*ms, direction=1)\n",
    "segment = np.linspace(-1.0, 1.0, num=401)*pq.s\n",
    "plt.plot(segment, kernel(segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (16.0, 6.0)\n",
    "kernel_types = [obj for obj in kernels.__dict__.values() if isinstance(obj, type) and issubclass(obj, kernels.Kernel) and hasattr(obj, \"_evaluate\") and obj is not kernels.Kernel and obj is not kernels.SymmetricKernel]\n",
    "# print(kernel_types)\n",
    "kernel_list = [kernel_type(sigma=10*ms, direction=1) for kernel_type in kernel_types]\n",
    "segment = np.linspace(-40, 40, 101)*ms\n",
    "bin_width = segment[1] - segment[0]\n",
    "for j, kernel in enumerate(kernel_list):\n",
    "    plt.subplot(2, 4, j + 1)\n",
    "    plt.bar(segment, kernel(segment).magnitude, width=bin_width, color='rgbymck'[j], lw=0)\n",
    "    plt.title(kernel.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantaneous Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statistics_dev import instantaneous_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = kernels.RectangularKernel(sigma=100*ms, direction=1)\n",
    "rate = instantaneous_rate(spikes, signal.sampling_period, k)\n",
    "plt.plot(rate.times, rate)\n",
    "plt.xlabel(rate.times.units)\n",
    "plt.ylabel(rate.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generating random spike trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from elephant.spike_train_generation import homogeneous_gamma_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spiketrains = [homogeneous_gamma_process(2.0, 50*Hz, 0*ms, 1000*ms)\n",
    "               for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, spiketrain in enumerate(spiketrains):\n",
    "    plt.plot(spiketrain, i * np.ones_like(spiketrain), '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from elephant.spike_train_correlation import corrcoef\n",
    "from elephant.conversion import BinnedSpikeTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spiketrains[75:80] = [spiketrains[25]]*5   # introduce some correlations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i, spiketrain in enumerate(spiketrains):\n",
    "    plt.plot(spiketrain, i * np.ones_like(spiketrain), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "binned_spikes = BinnedSpikeTrain(spiketrains, binsize=5*ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binned_spikes.to_bool_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cc_matrix = corrcoef(binned_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "plt.imshow(cc_matrix, cmap=cm.hot)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('./elephant_dev/')\n",
    "from spike_train_correlation_dev import cross_correlation_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CCH = cross_correlation_histogram(\n",
    "        BinnedSpikeTrain(spiketrains[76],binsize= 2*ms),BinnedSpikeTrain(spiketrains[78],binsize = 2*ms)\n",
    "        ,window=[-100,100])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.bar(left=CCH.times.magnitude,height=CCH[:, 0].magnitude,width=CCH.sampling_period.magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pairwise and higher order synchrony"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unitary Event analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neo.io import NeoHdf5IO\n",
    "import unitary_event_analysis_dev as ue\n",
    "import plot_uitary_events as plot_ue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "block = NeoHdf5IO(\"data/Data_experiment.h5\")\n",
    "sts1 = block.read_segment().segments[0].spiketrains\n",
    "sts2 = block.read_segment().segments[1].spiketrains\n",
    "spiketrains = np.vstack((sts1,sts2)).T\n",
    "\n",
    "print 'calculating UE ...'\n",
    "UE = ue.jointJ_window_analysis(spiketrains, binsize=5*ms, winsize=100*ms, winstep=10*ms,\n",
    "                                pattern_hash = [3])\n",
    "\n",
    "plot_ue._plot_UE(\n",
    "        spiketrains,UE,ue.jointJ(0.05),binsize=5*ms,winsize=100*ms,winstep=10*ms,\n",
    "        pat=ue.inverse_hash_from_pattern([3], N=2), N=2,\n",
    "        t_winpos=ue._winpos(0*ms,spiketrains[0][0].t_stop,winsize=100*ms,winstep=10*ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compund Poisson Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import stocmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the amplitude distribution of the model\n",
    "A = np.zeros(101) \n",
    "A[[1,10]] = .96, .04\n",
    "\n",
    "# Generate the CPP data\n",
    "cpp = stocmod.cpp(A, t_stop=10000*ms, rate=20*Hz)\n",
    "\n",
    "# Compute the population histogram and the complexity distribution\n",
    "pophist = time_histogram(cpp, binsize=2*ms)\n",
    "complexity_cpp = np.histogram(\n",
    "        pophist.magnitude, bins=range(0, len(cpp)+2),normed = 1)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.subplot(2,1,1)\n",
    "for i, spiketrain in enumerate(cpp):\n",
    "    plt.plot(spiketrain, i * np.ones_like(spiketrain), ',',color = 'b')\n",
    "plt.xlim(0,2000)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(complexity_cpp[1][1:len(A)+1], A, color='r', label='amplitude distrib.')\n",
    "plt.plot(complexity_cpp[1][1:], complexity_cpp[0], label='complexity distrib.')\n",
    "plt.ylim([0, 0.25])\n",
    "plt.xlabel('probability', size=12)\n",
    "plt.ylabel('complexity', size=12)\n",
    "plt.suptitle('CPP', size=14)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pophist = time_histogram(cpp, binsize=1*ms)\n",
    "xi, p, k = cubic.cubic(pophist, alpha=0.05)\n",
    "\n",
    "xi_true = np.where([A>0])[-1][-1]\n",
    "\n",
    "ax = plt.subplot(121)\n",
    "ax.bar(left=np.arange(.5, len(p)+.5), height=p, color='darkgreen')\n",
    "ax.set_xlim(.5, len(p)+.5)\n",
    "ax.plot(ax.get_xlim(), [0.05, 0.05], 'r--', lw=2)\n",
    "ax.text(.1, .9, r'$\\hat\\xi=%d$ $(\\xi_{true}=%d)$' %(xi, xi_true), \n",
    "        transform=ax.transAxes, size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- spike train metrics (Victor-Purpura distance, Van Rossum distance, ...)\n",
    "- spike train covariance\n",
    "- frequent itemset mining (*cf* Torre et al. 2013)\n",
    "- signal coherence\n",
    "- generation of correlated random spike trains\n",
    "- support for optical imaging data\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goals of Elephant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- develop a free library of well-tested data analysis methods for neuroscience\n",
    "- stop reinventing the wheel\n",
    "\n",
    "![](figs/cavemen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Contributing to Neo and Elephant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Reporting bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   \n",
    "- https://github.com/NeuralEnsemble/python-neo/issues\n",
    "- https://github.com/NeuralEnsemble/elephant/issues\n",
    "\n",
    "![](figs/neo_issue_tracker.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Contributing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](figs/fork.png)\n",
    "\n",
    "- keep your own, customized version of Elephant\n",
    "- when you feel ready, submit a \"pull request\"\n",
    "- after code review, your functions are merged into the main Elephant release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thanks\n",
    "\n",
    "The following people have contributed code and/or ideas to the current version of Elephant.\n",
    "\n",
    "- Alper Yegenoglu [1]\n",
    "- Andrew Davison [2]\n",
    "- Detlef Holstein [2]\n",
    "- Eilif Muller [3, 4]\n",
    "- Emiliano Torre [1]\n",
    "- Julia Sprenger [1]\n",
    "- Junji Ito [1]\n",
    "- Michael Denker [1]\n",
    "- Paul Chorley [1]\n",
    "- Pierre Yger [2]\n",
    "- Pietro Quaglio [1]\n",
    "- Richard Meyes [1]\n",
    "- Vahid Rostami [1]\n",
    "- Subhasis Ray [5]\n",
    "\n",
    "\n",
    "1. Institute of Neuroscience and Medicine (INM-6), Computational and Systems Neuroscience & Institute for Advanced Simulation (IAS-6), Theoretical Neuroscience, Jülich Research Centre and JARA, Jülich, Germany\n",
    "2. Unité de Neurosciences, Information et Complexité, CNRS UPR 3293, Gif-sur-Yvette, France\n",
    "3. Electronic Visions Group, Kirchhoff-Institute for Physics, University of Heidelberg, Germany\n",
    "4. Brain-Mind Institute, Ecole Polytechnique Fédérale de Lausanne, Switzerland\n",
    "5. NIH–NICHD, Laboratory of Cellular and Synaptic Physiology, Bethesda, Maryland 20892"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following people have contributed code and/or ideas to the current version of Neo.\n",
    "\n",
    "- Samuel Garcia [1]\n",
    "- Andrew Davison [2]\n",
    "- Chris Rodgers [3]\n",
    "- Pierre Yger [2]\n",
    "- Yann Mahnoun [4]\n",
    "- Luc Estabanez [2]\n",
    "- Andrey Sobolev [5]\n",
    "- Thierry Brizzi [2]\n",
    "- Florent Jaillet [6]\n",
    "- Philipp Rautenberg [5]\n",
    "- Thomas Wachtler [5]\n",
    "- Cyril Dejean [7]\n",
    "- Robert Pröpper [8]\n",
    "- Domenico Guarino [2]\n",
    "\n",
    "\n",
    "1. Centre de Recherche en Neuroscience de Lyon, CNRS UMR5292 - INSERM U1028 - Universite Claude Bernard Lyon 1\n",
    "2. Unité de Neuroscience, Information et Complexité, CNRS UPR 3293, Gif-sur-Yvette, France\n",
    "3. University of California, Berkeley\n",
    "4. Laboratoire de Neurosciences Intégratives et Adaptatives, CNRS UMR 6149 - Université de Provence, Marseille, France\n",
    "5. G-Node, Ludwig-Maximilians-Universität, Munich, Germany\n",
    "6. Institut de Neurosciences de la Timone, CNRS UMR 7289 - Université d’Aix-Marseille, Marseille, France\n",
    "7. Centre de Neurosciences Integratives et Cognitives, UMR 5228 - CNRS - Université Bordeaux I - Université Bordeaux II\n",
    "8. Neural Information Processing Group, TU Berlin, Germany"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
